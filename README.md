### やったこと
* 与えられたデータから分類モデルを生成
* 入力ベクトルは1000次元。クラス数は2

### 使用したもの
* Chainer
  * 特徴
    * 順伝播は単純に Python のスクリプトとして書ける
    * 逆伝播を⼿で書く必要はない(そのスクリプトの実⾏行行結果は計算⼿手順を記憶している)

### 設計
* まずニューラルネットワークをきちんと取り組んだことが今までないので、比較的容易に理解が可能と思われたChainerを使用。
* [2]を参考にし、とりあえず隠れ層は2層.
* シンプルな分類モデルなのでRNNやCNNは使わずシンプルなネットワークにした。結合方法もシンプルに全結合のみを用いている
* 活性化関数は[3]を参考にしてReluを使用
* [4][5]曰く、誤差関数に関してはChainerは多く記述する必要がなさそうなので、今回は考慮しない
*

### 頑張ったこと
* NNを覚えた。層の数、層のユニットの数、最適化手法、活性化関数は自分で設定しないといけないことを学んだ。
* なぜNNで学習できるのかがよくわかっていないため、上で述べた設定しないといけないものは(層の数と活性化関数を除いて)総当たりでやるしかないことを突き止めた
* グリッドサーチで頑張った

### 結果
* 結果94%まで精度を上げることができた
* AdaGrad 200 300 acc test  0.941200017929



### 参考URL
* NNを知るために
[1] http://hi-king.hatenablog.com/entry/2015/06/27/194630
* MNISTのモデルの記事。
[2] http://qiita.com/_329_/items/bcc306194d52f7b81b5a
* 活性化関数
[3] http://www.slideshare.net/spade630/ss-51681817
* 順伝搬,逆伝搬
[4] http://ailaby.com/chainer_foward_backward/
* chainer
[5] http://www.slideshare.net/unnonouno/chainer-55494686
* 最適化とは
[6] http://www.iandprogram.net/entry/2016/02/11/181322
